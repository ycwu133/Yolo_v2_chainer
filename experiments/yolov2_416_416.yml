end_trigger: [200000, "iteration"] # 3200 / 16 = 200 * 150 = 30000
results: results
gpus: [1]
mode: Train
seed: 1

model:
  module: models.base_model
  name: SFMLearner
  pretrained_model:
    path: # 0000_model.npz
    download: # https://0000_model.npz
  architecture:
    smooth_reg: 0.5
    exp_reg: 0

dataset:
  train:
    module: datasets.coco.coco_detection_dataset
    name: CocoDetectionDataset
    args:
      root_dir: ../dataset/COCO
      data_dir: train2014
      anno_file: annotations/instances_train2014.json

  valid:
    module: datasets.coco.coco_detection_dataset
    name: CocoDetectionDataset
  args:
    root_dir: ../dataset/COCO
    data_dir: val2014
    anno_file: annotations/instances_val2014.json

updater:
  name: StandardUpdater

iterator:
  name: SerialIterator #MultiprocessIterator
  train_batchsize: 4
  test_batchsize: 4
  # args:
  #  n_processes: 4
  #  n_prefetch: 1
  #  shared_mem: 60000000

optimizer:
  name: Adam
  args:
    alpha: 0.0002
    beta1: 0.9
    beta2: 0.999
  hook:
    WeightDecay: 0.0005

extension:
  #Evaluator:
  #  name: Evaluator
  #  trigger: [1, 'epoch']
  snapshot:
      trigger: [200000, "iteration"]
  snapshot_object:
      trigger: [10000, "iteration"]
  LogReport:
    trigger: [100, "iteration"]
  PrintReport:
    name:
      epoch
      iteration
      main/total_loss
      main/pixel_loss
      main/smooth_loss
      main/exp_loss
    trigger: [100, "iteration"]
  ProgressBar:
      update_interval: 10
  observe_lr:
